{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPhD3tBWYP9G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Remember to use GPU!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTHIFLwUYP9b"
      },
      "source": [
        "### Load and scale the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOf98xw7YP9d"
      },
      "outputs": [],
      "source": [
        "feature = pd.read_csv('https://raw.githubusercontent.com/xchen793/NYU22SummerSchoolML/main/Day5/fish_market_feature.csv')\n",
        "label = pd.read_csv('https://raw.githubusercontent.com/xchen793/NYU22SummerSchoolML/main/Day5/fish_market_label.csv')\n",
        "X = feature.values\n",
        "y = label.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcLBSg0IwTC4"
      },
      "outputs": [],
      "source": [
        "# normalize the data using sklearn's StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "Xs = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CiQzBuFwTC4"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "# split the SCALED!! data in validation and train\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(Xs, y, test_size=0.1, random_state=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csPADzrBwTC5"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "# print the number of data samples in the training and validation data\n",
        "print(f\"The number of data samples in the training data is: {X_train.shape[0]}\")\n",
        "print(f\"The number of data samples in the validation data is: {X_val.shape[0]}\")\n",
        "\n",
        "print(f\"The number of features is: {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd-R6M1YP9s"
      },
      "source": [
        "### Build Model\n",
        "\n",
        "1) Define a model of three dense layers with ReLu activation functions. The output of the two first layers should have 32 neurons. \n",
        "\n",
        "2) Train the model for 2000 epochs with a batch size of 64 and a mean squared error loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlKXS0cMeMcp"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "n_epochs = 2000\n",
        "batch_size = 64\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(5,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error',\n",
        "    metrics=['mse', 'mae']\n",
        ") # use the Adam optimizer\n",
        "\n",
        "# print a summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJs08w07wTC8"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "# train the model (use the train data and validation data from above)\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=n_epochs, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE6OhAFqwTC9"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "# plot the train and validation losses on the same picture\n",
        "# make sure to label the axis and create a legend \n",
        "plt.figure(figsize=(8,6))\n",
        "plt.semilogy(np.arange(n_epochs), history.history['loss'], label='Train Loss', linewidth=2)\n",
        "plt.semilogy(np.arange(n_epochs), history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train/Val Loss')\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6kC3IVHYP-E"
      },
      "source": [
        "#### Load the testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWgUAW_mYP-F"
      },
      "outputs": [],
      "source": [
        "X_test = pd.read_csv('https://raw.githubusercontent.com/xchen793/NYU22SummerSchoolML/main/Day5/fish_market_test_feature.csv').values\n",
        "y_test = pd.read_csv('https://raw.githubusercontent.com/xchen793/NYU22SummerSchoolML/main/Day5/fish_market_test_label.csv').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUqvkyFBwTC_"
      },
      "outputs": [],
      "source": [
        "# scale the test data using the scaler above\n",
        "Xtest_s = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWVPrrD4wTC_"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "# predict the corresponding y_hat value of the test dataset (use the scaled test data)\n",
        "y_hat = model.predict(Xtest_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8hiFtuwYP-P"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(np.arange(y_hat.shape[0]), y_hat, label='Prediction')\n",
        "plt.scatter(np.arange(y_test.shape[0]), y_test, label='Ground Truth')\n",
        "plt.legend()\n",
        "plt.xlabel('data no.')\n",
        "plt.ylabel('predicted value')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPIapp0GwTDA"
      },
      "outputs": [],
      "source": [
        "## TODO\n",
        "# print MSE, RMSE (root-mse), MAE on the train and test data\n",
        "# compare these results against last week's results (when we used linear/polynimial regression)\n",
        "y_hat_train = model.predict(X_train)\n",
        "mse_train = np.mean((y_train - y_hat_train)**2)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "mae_train = np.mean(np.abs(y_train - y_hat_train))\n",
        "\n",
        "mse_test = np.mean((y_test - y_hat)**2)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "mae_test = np.mean(np.abs(y_test - y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_6FW_nhwTDA"
      },
      "outputs": [],
      "source": [
        "print(f\"The Train MSE is: {mse_train}\")\n",
        "print(f\"The Train Root MSE is: {rmse_train}\")\n",
        "print(f\"The Train MAE is: {mae_train}\")\n",
        "print('----------')\n",
        "print(f\"The Test MSE is: {mse_test}\")\n",
        "print(f\"The Test Root MSE is: {rmse_test}\")\n",
        "print(f\"The Test MAE is: {mae_test}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "“lab_mlp_fish_market_keras.ipynb”的副本",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}